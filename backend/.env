OLLAMA_HOST=http://localhost:11434
LLM_MODEL=llama3.2 # Or whatever Llama model you have pulled with Ollama